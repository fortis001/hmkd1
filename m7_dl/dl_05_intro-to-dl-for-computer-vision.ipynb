{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2q+oi5QCf+iusnLA21bX4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **컴퓨터 비전을 위한 딥러닝**"],"metadata":{"id":"uva3HX1v8Zvi"}},{"cell_type":"markdown","source":["## 합성곱 신경망 소개\n","\n","혼공 p437 참조\n","\n","\n","합성곱 신경망(Convolutional Neural Networks, CNN)은 이미지나 비디오 등의 공간적 구조를 가진 데이터를 처리하는 데 유용한 딥러닝 모델\n","\n","- 입력 레이어: 원시 이미지 데이터를 받아들이는 첫 번째 레이어. 이미지는 보통 높이, 너비, 그리고 색상 채널(예: RGB)의 3차원 텐서로 표현.\n","\n","- 합성곱 레이어(Convolutional Layer): 이 레이어는 이미지의 지역적 특성을 학습. 이 레이어에서는 \"필터\" 또는 \"커널\"이라는 작은 윈도우가 이미지를 스캔하며 이동. 각 필터는 고유한 특징(예: 가장자리, 텍스처 등)을 인식.\n","\n","- 필터/커널: 합성곱 층에서 사용되는 작은 행렬로, 랜덤한 값으로 초기화된 후에 데이터를 통해 학습. 필터는 이미지의 여러 부분을 스캔하며 특정 특징을 인식.\n","\n","- 스트라이드: 필터가 이미지 위를 이동하는 간격. 스트라이드 값에 따라 출력 피쳐 맵의 크기가 결정되며 큰 스트라이드는 작은 출력 차원을 생성하고, 작은 스트라이드는 큰 출력 차원을 생성.\n","\n","- 패딩: 입력 이미지의 주위에 픽셀을 추가하는 방법으로, 합성곱이 적용된 후의 출력 크기를 조절할 수 있다. 패딩이 없으면 합성곱 연산을 거치면서 출력 이미지의 크기가 작아진다. 패딩을 사용하면 이를 방지하고 원본 이미지의 공간적 크기를 보존할 수 있다.\n","\n","- 활성화 함수: 일반적으로 ReLU(Rectified Linear Unit) 같은 비선형 활성화 함수가 사용되어 복잡한 패턴을 학습할 수 있도록 한다.\n","\n","- 풀링 레이어(Pooling Layer): 이 레이어는 출력을 다운샘플링하여 모델의 복잡도를 줄이고, 과적합을 방지하며, 일부 공간적 인식력을 보존. 가장 많이 사용되는 풀링 방법은 최대 풀링(Max Pooling)이다.\n","\n","- 완전 연결 레이어(Fully Connected Layer): 이 레이어는 모든 입력 뉴런이 모든 출력 뉴런과 연결되어 있다. 이는 일반적으로 신경망의 마지막 단계에서 사용되며, 합성곱 및 풀링 레이어를 통해 학습된 고차원 특징을 이용하여 최종적으로 분류나 회귀 등의 작업을 수행.\n","\n","- 이러한 각 요소들이 어떻게 함께 작동하는지 간단하게 설명하면, 합성곱 레이어의 필터는 입력 이미지를 스캔하면서 지역적인 특징을 감지하고, 이 정보를 활성화 맵(특징 맵)의 형태로 출력. 이때, 스트라이드와 패딩은 필터가 이미지를 어떻게 스캔할지를 결정하며, 활성화 함수는 비선형성을 추가하여 복잡한 패턴을 학습하게 해준다. 그 다음, 풀링 레이어는 이 특징 맵을 다운샘플링하여 모델의 복잡도를 줄이고, 공간적 인식력을 보존하며, 과적합을 방지한다. 마지막으로, 완전 연결 레이어는 이런 모든 특징들을 종합하여 최종적으로 이미지의 클래스를 예측하거나, 객체의 위치를 회귀하는 등의 작업을 수행한다.\n","이런 식으로, CNN은 각 레이어에서 이미지의 다양한 특징을 학습하고, 이 정보를 바탕으로 복잡한 패턴을 인식하고, 효과적인 예측을 수행하게 됩니다.\n","\n","- 2D 합성곱 (Conv2D): 이는 가장 흔히 사용되는 합성곱 유형으로, 이미지 같은 2차원 데이터에 적용. Conv2D는 입력 데이터의 지역적 특징을 인식하고 이를 학습하는 데 사용.\n","\n","- 1D 합성곱 (Conv1D): 이 유형의 합성곱은 시퀀스 데이터(예: 시계열 데이터, 텍스트 데이터)를 처리하는 데 주로 사용. 이는 입력 시퀀스의 연속적인 부분을 고려하므로, 특히 시간적인 순서 정보가 중요한 문제에 유용."],"metadata":{"id":"EsCvf1348esb"}},{"cell_type":"markdown","source":["간단한 컴브넷 만들기"],"metadata":{"id":"44K-WB_6JrRZ"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"t-0YI8468HOp","executionInfo":{"status":"ok","timestamp":1688956309681,"user_tz":-540,"elapsed":393,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","inputs = keras.Input(shape=(28, 28, 1)) # (28, 28, 1) 형태의 3차원 텐서를 입력\n","#  32개의 3x3 크기의 필터를 사용하는 합성곱 레이어를 정의하고, 입력 이미지에 적용\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x) # 텐서를 1차원으로 평탄화해서 모든 픽셀 값들을 연속적인 벡터 형태로 변환\n","# 출력 레이어로 완전 연결 레이어로, 10개의 뉴런을 가지며 각 뉴런은 이미지가 특정 클래스에 속할 확률을 출력\n","outputs = layers.Dense(10, activation=\"softmax\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)"]},{"cell_type":"markdown","source":["모델의 summary() 메서드 출력"],"metadata":{"id":"dW3JknBxJxYI"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OtV2T8uJwpq","executionInfo":{"status":"ok","timestamp":1688956309681,"user_tz":-540,"elapsed":10,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"9f043b30-5274-4828-efff-9ab98515ea2e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 3, 3, 128)         73856     \n","                                                                 \n"," flatten_2 (Flatten)         (None, 1152)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                11530     \n","                                                                 \n","=================================================================\n","Total params: 104,202\n","Trainable params: 104,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["MNIST 이미지에서 컨브넷 훈련하기"],"metadata":{"id":"7W_w2LddJ1_Q"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype(\"float32\") / 255\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype(\"float32\") / 255\n","model.compile(optimizer=\"rmsprop\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"])\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-VkIUO3aJzph","executionInfo":{"status":"ok","timestamp":1688956694216,"user_tz":-540,"elapsed":384538,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"936a7d3a-438a-4774-a76a-e346c6c24857"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","938/938 [==============================] - 71s 74ms/step - loss: 0.1616 - accuracy: 0.9499\n","Epoch 2/5\n","938/938 [==============================] - 65s 69ms/step - loss: 0.0461 - accuracy: 0.9861\n","Epoch 3/5\n","938/938 [==============================] - 64s 68ms/step - loss: 0.0321 - accuracy: 0.9899\n","Epoch 4/5\n","938/938 [==============================] - 64s 69ms/step - loss: 0.0234 - accuracy: 0.9928\n","Epoch 5/5\n","938/938 [==============================] - 62s 66ms/step - loss: 0.0182 - accuracy: 0.9946\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f36493c4340>"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["컨브넷 평가하기"],"metadata":{"id":"Q-v8pX56J43A"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CZytVrxJ3oY","executionInfo":{"status":"ok","timestamp":1688956698946,"user_tz":-540,"elapsed":4745,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"90ccfc21-ca08-4a43-bab8-60691bddb28b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 5s 15ms/step - loss: 0.0256 - accuracy: 0.9922\n","테스트 정확도: 0.992\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"aTzOlY9-atXw"}},{"cell_type":"markdown","source":["# 합성곱 연산\n","## 경계 문제와 패딩 이해하기\n","## 합성곱 스트라이등 이해하기\n","# 최대 풀링 연산\n","**최대 풀링 층이 빠진 잘못된 구조의 컨브넷**\n","\n","맥스 풀링을 하지 않을 경우 다음과 같은 문제가 발생할 수 있습니다:\n","\n","- 과적합: 맥스 풀링은 이미지의 크기를 줄이고, 따라서 모델이 학습해야 하는 파라미터의 수를 줄입니다. 이는 모델의 복잡도를 낮추고, 과적합(overfitting)을 방지하는 데 도움이 됩니다. 맥스 풀링을 사용하지 않으면, 모델은 더 많은 파라미터를 가지게 되어 과적합의 위험이 커집니다.\n","\n","- 계산 효율성 감소: 맥스 풀링을 통해 이미지 크기를 줄이면, 그 이후의 합성곱 레이어에서 처리해야 하는 데이터의 양이 줄어듭니다. 이는 계산 효율성을 향상시키는 데 도움이 됩니다. 맥스 풀링을 사용하지 않으면, 계산 비용이 크게 증가할 수 있습니다.\n","\n","- 공간적 인변성 감소: 맥스 풀링은 이미지의 작은 변화, 예를 들어 객체의 위치 변화에 대해 모델이 덜 민감하게 만듭니다. 이는 객체가 이미지의 어느 위치에 있든지 간에 그 객체를 감지하는 데 도움이 됩니다. 맥스 풀링을 사용하지 않으면, 모델은 이런 작은 변화에 더 민감해지며, 이는 성능을 저하시킬 수 있습니다."],"metadata":{"id":"pqSpvv3uJ7_B"}},{"cell_type":"code","source":["inputs = keras.Input(shape=(28, 28, 1))\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(10, activation=\"softmax\")(x)\n","model_no_max_pool = keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"Uu1-mEgJJ6XA","executionInfo":{"status":"ok","timestamp":1688956698946,"user_tz":-540,"elapsed":29,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model_no_max_pool.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZWDuAOwKKuy","executionInfo":{"status":"ok","timestamp":1688956699450,"user_tz":-540,"elapsed":530,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"8fa07064-c2ac-4e9b-de4f-06b1036856bf"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 24, 24, 64)        18496     \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 22, 22, 128)       73856     \n","                                                                 \n"," flatten_3 (Flatten)         (None, 61952)             0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                619530    \n","                                                                 \n","=================================================================\n","Total params: 712,202\n","Trainable params: 712,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기\n","# 작은 데이터셋 문제에서 딥러닝의 타당성\n","## 데이터 내려받기\n","캐글에서 dogs-vs-cats 데이터셋을 다운로드하려면 캐글에 가입해야 한 후 생성한 API 키를 사용해야 합니다. 이런 과정이 번거롭다면 다음 명령으로 구글 드라이브에서 직접 다운로드할 수 있습니다."],"metadata":{"id":"xiMH7De9KZnw"}},{"cell_type":"code","source":["import gdown\n","gdown.download(id='18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd', output='dogs-vs-cats.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"flIkd58FKW1g","executionInfo":{"status":"ok","timestamp":1688956710693,"user_tz":-540,"elapsed":11261,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"8691d800-641a-47c0-afe4-aa6323917a28"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=18uC7WTuEXKJDDxbj-Jq6EjzpFrgE7IAd\n","To: /content/dogs-vs-cats.zip\n","100%|██████████| 852M/852M [00:10<00:00, 78.1MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["'dogs-vs-cats.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# kaggle.json 파일을 업로드하세요.\n","# from google.colab import files\n","# files.upload()"],"metadata":{"id":"VyCyKnTrRwyB","executionInfo":{"status":"ok","timestamp":1688956710694,"user_tz":-540,"elapsed":10,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# !mkdir ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# !chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"J9CJVXW1Rwvw","executionInfo":{"status":"ok","timestamp":1688956710695,"user_tz":-540,"elapsed":9,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# !kaggle competitions download -c dogs-vs-cats"],"metadata":{"id":"Jk4YRY52RwtQ","executionInfo":{"status":"ok","timestamp":1688956710695,"user_tz":-540,"elapsed":9,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["!unzip -qq dogs-vs-cats.zip # qq' 옵션은 'quiet' 모드로 unzip 명령어가 해제 과정의 세부 정보를 출력하지 않습니다.\n","!unzip -qq train.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HY44BbCtRwqg","executionInfo":{"status":"ok","timestamp":1688956856284,"user_tz":-540,"elapsed":145597,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"15309d44-a999-47cb-a149-88dff6487057"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["replace sampleSubmission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","A\n","A\n","A\n","A\n","replace train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIN2tiv_R1Dh","executionInfo":{"status":"ok","timestamp":1688956856285,"user_tz":-540,"elapsed":55,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"65539152-44c7-49ac-8a90-b5aeb3b46d01"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mcats_vs_dogs_small\u001b[0m/  \u001b[01;34msample_data\u001b[0m/          test1.zip  train.zip\n","dogs-vs-cats.zip     sampleSubmission.csv  \u001b[01;34mtrain\u001b[0m/\n"]}]},{"cell_type":"markdown","source":["**이미지를 훈련, 검증, 테스트 디렉토리로 복사하기**\n","\n","코드를 실행하면, 'cats_vs_dogs_small' 디렉토리 아래에 'cat'과 'dog' 각각의 이미지가 포함된 'train', 'validation', 'test' 세 개의 서브 디렉토리가 생성됩니다. 이렇게 하면 원본 이미지 데이터셋의 일부를 추출하여 새로운, 더 작은 데이터셋을 만드는 데 유용"],"metadata":{"id":"U-MnrtbHRluI"}},{"cell_type":"code","source":["!rm -r cats_vs_dogs_small/train/cat"],"metadata":{"id":"a2qsmD25rQ15","executionInfo":{"status":"ok","timestamp":1688956901600,"user_tz":-540,"elapsed":372,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# 원본 이미지 데이터셋에서 일부 데이터를 추출하여 새로운 하위 데이터셋을 생성.\n","# 이 하위 데이터셋은 훈련, 검증, 테스트의 세 가지 부분으로 구성\n","import os, shutil, pathlib\n","\n","original_dir = pathlib.Path(\"train\") # 'train' 폴더를 원본 데이터셋의 디렉토리로 설정\n","new_base_dir = pathlib.Path(\"cats_vs_dogs_small\") # 'cats_vs_dogs_small' 폴더를 새로운 데이터셋의 베이스 디렉토리로 설정\n","\n","def make_subset(subset_name, start_index, end_index):\n","    for category in (\"cat\", \"dog\"): # 각 카테고리에 대해 작업을 수행\n","        dir = new_base_dir / subset_name / category # 각 카테고리의 새로운 디렉토리 경로를 생성\n","        os.makedirs(dir)\n","        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n","        for fname in fnames:\n","            shutil.copyfile(src=original_dir / fname,\n","                            dst=dir / fname) # 원본 디렉토리에서 해당 파일을 복사하여 새 디렉토리에 붙여넣기\n","\n","make_subset(\"train\", start_index=0, end_index=1000)\n","make_subset(\"validation\", start_index=1000, end_index=1500)\n","make_subset(\"test\", start_index=1500, end_index=2500)"],"metadata":{"id":"GZxhdfslKfoa","executionInfo":{"status":"ok","timestamp":1688956905404,"user_tz":-540,"elapsed":847,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["!ls cats_vs_dogs_small/"],"metadata":{"id":"6kQ16oxDR5P4","executionInfo":{"status":"ok","timestamp":1688956912327,"user_tz":-540,"elapsed":342,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"442a9141-dbae-4198-d895-92d43c031308"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["test  train  validation\n"]}]},{"cell_type":"markdown","source":["# 모델 만들기\n","강아지 vs. 고양이 분류를 위한 소규모 컨브넷 만들기"],"metadata":{"id":"9yyD-j-nZAQf"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","inputs = keras.Input(shape=(180, 180, 3)) # 높이와 너비가 각각 180 픽셀이며 3개의 채널(RGB)을 가진 이미지 입력\n","x = layers.Rescaling(1./255)(inputs) # 입력 이미지의 픽셀 값을 [0, 1] 범위로 재조정\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) # 32개의 필터를 사용하며, 각 필터의 크기는 3x3\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"i5qfl9rEY8jY","executionInfo":{"status":"ok","timestamp":1688956916194,"user_tz":-540,"elapsed":329,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"_bhAZA6ZZDOH","executionInfo":{"status":"ok","timestamp":1688956919110,"user_tz":-540,"elapsed":526,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bff41bb2-8c1c-408f-a0fc-57441f0e92ee"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 180, 180, 3)]     0         \n","                                                                 \n"," rescaling (Rescaling)       (None, 180, 180, 3)       0         \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 178, 178, 32)      896       \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 89, 89, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 87, 87, 64)        18496     \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 43, 43, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 41, 41, 128)       73856     \n","                                                                 \n"," max_pooling2d_6 (MaxPooling  (None, 20, 20, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_15 (Conv2D)          (None, 18, 18, 256)       295168    \n","                                                                 \n"," max_pooling2d_7 (MaxPooling  (None, 9, 9, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_16 (Conv2D)          (None, 7, 7, 256)         590080    \n","                                                                 \n"," flatten_4 (Flatten)         (None, 12544)             0         \n","                                                                 \n"," dense_4 (Dense)             (None, 1)                 12545     \n","                                                                 \n","=================================================================\n","Total params: 991,041\n","Trainable params: 991,041\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["**모델 훈련 설정하기**"],"metadata":{"id":"heu7WjIyZH2H"}},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"i39i-xKIZEhn","executionInfo":{"status":"ok","timestamp":1688956922694,"user_tz":-540,"elapsed":540,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 전처리\n","**image_dataset_from_directory를 사용하여 이미지 읽기**\n","\n","TensorFlow Keras의 image_dataset_from_directory 함수를 사용하여 디렉토리에 저장된 이미지 데이터로부터 데이터셋을 생성"],"metadata":{"id":"1UIiLOpEswyI"}},{"cell_type":"code","source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","# 'new_base_dir / \"train\"' 경로에서 훈련 데이터셋을 생성.\n","# 여기서 각 이미지의 크기는 180x180으로 조정되며, 한 번에 32개의 이미지를 포함하는 배치(batch)가 생성\n","train_dataset = image_dataset_from_directory(\n","    new_base_dir / \"train\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    new_base_dir / \"validation\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","test_dataset = image_dataset_from_directory(\n","    new_base_dir / \"test\",\n","    image_size=(180, 180),\n","    batch_size=32)"],"metadata":{"id":"u5cAg1ajZKWf","executionInfo":{"status":"ok","timestamp":1688957326787,"user_tz":-540,"elapsed":530,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2aad471-68bc-4862-a2a8-16b00979b842"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 files belonging to 2 classes.\n","Found 1000 files belonging to 2 classes.\n","Found 2000 files belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","random_numbers = np.random.normal(size=(1000, 16)) # 평균 0, 표준편차 1의 정규분포에서 랜덤하게 생성된 1000x16 크기의 2D 배열을 생성\n","dataset = tf.data.Dataset.from_tensor_slices(random_numbers) # Numpy 배열을 TensorFlow 데이터셋으로 변환"],"metadata":{"id":"1FzOP64Os461","executionInfo":{"status":"ok","timestamp":1688957331551,"user_tz":-540,"elapsed":348,"user":{"displayName":"SH L","userId":"11689349986031670759"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["for i, element in enumerate(dataset):\n","    print(element.shape)\n","    if i >= 2:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_pIEd7Us6R9","executionInfo":{"status":"ok","timestamp":1688957338071,"user_tz":-540,"elapsed":368,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"813e6333-0253-4044-f89a-909d1fb3a43c"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["(16,)\n","(16,)\n","(16,)\n"]}]},{"cell_type":"code","source":["batched_dataset = dataset.batch(32)\n","for i, element in enumerate(batched_dataset):\n","    print(element.shape)\n","    if i >= 2:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RkoAJFes72N","executionInfo":{"status":"ok","timestamp":1688957343420,"user_tz":-540,"elapsed":4,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"aee0b813-93f2-4889-bf77-da4494ebd352"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["(32, 16)\n","(32, 16)\n","(32, 16)\n"]}]},{"cell_type":"code","source":["reshaped_dataset = dataset.map(lambda x: tf.reshape(x, (4, 4)))\n","for i, element in enumerate(reshaped_dataset):\n","    print(element.shape)\n","    if i >= 2:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufXAwQoHs9KN","executionInfo":{"status":"ok","timestamp":1688957348513,"user_tz":-540,"elapsed":448,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"c6ae4d77-54c8-4e34-9d67-f8fa09c0bf78"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["(4, 4)\n","(4, 4)\n","(4, 4)\n"]}]},{"cell_type":"markdown","source":["Dataset이 반환하는 데이터와 레이블 크기 확인하기"],"metadata":{"id":"r9Us67FPs_1V"}},{"cell_type":"code","source":["for data_batch, labels_batch in train_dataset:\n","    print(\"데이터 배치 크기:\", data_batch.shape)\n","    print(\"레이블 배치 크기:\", labels_batch.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvyCS4Zss-Yd","executionInfo":{"status":"ok","timestamp":1688957361416,"user_tz":-540,"elapsed":839,"user":{"displayName":"SH L","userId":"11689349986031670759"}},"outputId":"5a30748a-e281-4084-f5a0-167f2f0ac857"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 배치 크기: (32, 180, 180, 3)\n","레이블 배치 크기: (32,)\n"]}]},{"cell_type":"markdown","source":["Dataset을 사용해 모델 훈련하기"],"metadata":{"id":"YsRz_ZDQtC6F"}},{"cell_type":"code","source":["# ModelCheckpoint 콜백을 사용하여 훈련 도중에 모델을 저장\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"convnet_from_scratch.keras\", # 저장된 파일의 이름\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=30,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aEWv-cKwtBdV","outputId":"b50271a1-af41-4c11-de37-bca399927aaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","63/63 [==============================] - 265s 4s/step - loss: 0.6999 - accuracy: 0.5225 - val_loss: 0.6885 - val_accuracy: 0.5080\n","Epoch 2/30\n","63/63 [==============================] - 220s 4s/step - loss: 0.6894 - accuracy: 0.5350 - val_loss: 0.9720 - val_accuracy: 0.5000\n","Epoch 3/30\n","63/63 [==============================] - 221s 4s/step - loss: 0.6811 - accuracy: 0.5835 - val_loss: 0.7189 - val_accuracy: 0.5390\n","Epoch 4/30\n","51/63 [=======================>......] - ETA: 34s - loss: 0.6520 - accuracy: 0.6238"]}]},{"cell_type":"markdown","source":["훈련 정확도와 손실 그래프 그리기"],"metadata":{"id":"_l1CiHgptF99"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","accuracy = history.history[\"accuracy\"]\n","val_accuracy = history.history[\"val_accuracy\"]\n","loss = history.history[\"loss\"]\n","val_loss = history.history[\"val_loss\"]\n","epochs = range(1, len(accuracy) + 1)\n","plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n","plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n","plt.title(\"Training and validation accuracy\")\n","plt.legend()\n","plt.figure()\n","plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n","plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n","plt.title(\"Training and validation loss\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"5KICdr5htEXd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트 세트에서 모델 평가하기"],"metadata":{"id":"CY-0RC8otI1m"}},{"cell_type":"code","source":["test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n","test_loss, test_acc = test_model.evaluate(test_dataset)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"],"metadata":{"id":"vTi-AL20tHcF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**컨브넷에 추가할 데이터 증식 단계 정의하기**\n","\n","세 가지 데이터 증강 기법\n","\n","- layers.RandomFlip(\"horizontal\"): 이미지를 수평 방향으로 무작위로 뒤집습니다. 이는 이미지에 대한 모델의 위치 불변성을 증가시키는 데 도움이 됩니다.\n","\n","- layers.RandomRotation(0.1): 이미지를 최대 0.1 라디안(약 5.7도) 범위에서 무작위로 회전시킵니다. 회전은 중심을 기준으로 하며, 빈 영역은 근접한 픽셀로 채워집니다.\n","\n","- layers.RandomZoom(0.2): 이미지를 최대 20% 범위에서 무작위로 확대/축소합니다. 빈 영역은 근접한 픽셀로 채워집니다."],"metadata":{"id":"UhDFeNLJmSiW"}},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(0.1),\n","        layers.RandomZoom(0.2),\n","    ]\n",")"],"metadata":{"id":"6TieDzQCmTsO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["랜덤하게 증식된 훈련 이미지 출력하기"],"metadata":{"id":"0cwbiHkZtPLe"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","for images, _ in train_dataset.take(1):\n","    for i in range(9):\n","        augmented_images = data_augmentation(images)\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n","        plt.axis(\"off\")"],"metadata":{"id":"Q8eu0TcltOHN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이미지 증식과 드롭아웃을 포함한 컨브넷 만들기"],"metadata":{"id":"lwCdwrPKtR_W"}},{"cell_type":"code","source":["inputs = keras.Input(shape=(180, 180, 3))\n","x = data_augmentation(inputs)\n","x = layers.Rescaling(1./255)(x)\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"DphHF98otQrN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["규제를 추가한 컨브넷 훈련하기"],"metadata":{"id":"F0IIaJEWtU12"}},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=100,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"],"metadata":{"id":"OTvJh1Z4tTll"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트 세트에서 모델 훈련하기"],"metadata":{"id":"BO1Dwr3KtYMN"}},{"cell_type":"code","source":["test_model = keras.models.load_model(\n","    \"convnet_from_scratch_with_augmentation.keras\")\n","test_loss, test_acc = test_model.evaluate(test_dataset)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"],"metadata":{"id":"jeu0njqttWZW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 사전 훈련된 모델 활용하기\n","**사전 훈련된 모델을 사용한 특성 추출**\n","\n","VGG16 합성곱 기반 층 만들기"],"metadata":{"id":"-YbklJoTtbIN"}},{"cell_type":"code","source":["conv_base = keras.applications.vgg16.VGG16(\n","    weights=\"imagenet\",\n","    include_top=False,\n","    input_shape=(180, 180, 3))"],"metadata":{"id":"Jkp5nBJ-tZpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"id":"jExyOXC6teqN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**데이터 증식을 사용하지 않는 빠른 특성 추출**\n","\n","VGG16 특성과 해당 레이블 추출하기"],"metadata":{"id":"aR-htAteth_P"}},{"cell_type":"code","source":["import numpy as np\n","\n","def get_features_and_labels(dataset):\n","    all_features = []\n","    all_labels = []\n","    for images, labels in dataset:\n","        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n","        features = conv_base.predict(preprocessed_images)\n","        all_features.append(features)\n","        all_labels.append(labels)\n","    return np.concatenate(all_features), np.concatenate(all_labels)\n","\n","train_features, train_labels =  get_features_and_labels(train_dataset)\n","val_features, val_labels =  get_features_and_labels(validation_dataset)\n","test_features, test_labels =  get_features_and_labels(test_dataset)"],"metadata":{"id":"BDp_XyJatf29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ARbJitjutlrN"},"execution_count":null,"outputs":[]}]}